{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find information about Proj_Milestone_ID 1.\n",
      "Action: Chat Bot\n",
      "Action Input: \"What are the details of Proj_Milestone_ID 1?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'answer': {'query': 'What are the details of Proj_Milestone_ID 1?', 'result': ' Proj_Milestone_ID 1 has a Project_ID of 1, a Status_Date of 01-06-2023 00:00, a Milestone_Phase of Select Phase Start, a Planned_Date of Monday, March 07, 2022, a Target_Date of Monday, March 07, 2022, a Completion_Percentage of 100, a Status of Completed, a RAG_Status of 4, an Actual_Start_Date of Monday, March 07, 2022, an Actual_End_Date of Tuesday, March 15, 2022, a Delayed of 8, an Updated_RAG_Status_After_Delay of 4, an Amber_To_Red_Status of 0, a Green_to_Amber_Status of 0, a Pred_Prob_for_Amber_to_Red_of_milestones of 0.014163588, and a Pred_Prob_for_Green_to_Amber_of_milestones of 0.006854209.'}}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the details of Proj_Milestone_ID 1.\n",
      "Final Answer: Proj_Milestone_ID 1 has a Project_ID of 1, a Status_Date of 01-06-2023 00:00, a Milestone_Phase of Select Phase Start, a Planned_Date of Monday, March 07, 2022, a Target_Date of Monday, March 07, 2022, a Completion_Percentage of 100, a Status of Completed, a RAG_Status of 4, an Actual_Start_Date of Monday, March 07, 2022, an Actual_End_Date of Tuesday, March 15, 2022, a Delayed of 8, an Updated_RAG_Status_After_Delay of 4, an Amber_To_Red_Status of 0, a Green_to_Amber_Status of 0, a Pred_Prob_for_Amber_to_Red_of_milestones of 0.014163588, and a Pred_Prob_for_Green_to_Amber_of_milestones of 0.006854209.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'give me detal of Proj_Milestone_ID is 1', 'output': 'Proj_Milestone_ID 1 has a Project_ID of 1, a Status_Date of 01-06-2023 00:00, a Milestone_Phase of Select Phase Start, a Planned_Date of Monday, March 07, 2022, a Target_Date of Monday, March 07, 2022, a Completion_Percentage of 100, a Status of Completed, a RAG_Status of 4, an Actual_Start_Date of Monday, March 07, 2022, an Actual_End_Date of Tuesday, March 15, 2022, a Delayed of 8, an Updated_RAG_Status_After_Delay of 4, an Amber_To_Red_Status of 0, a Green_to_Amber_Status of 0, a Pred_Prob_for_Amber_to_Red_of_milestones of 0.014163588, and a Pred_Prob_for_Green_to_Amber_of_milestones of 0.006854209.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.utilities import SerpAPIWrapper, SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "import os\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "\n",
    "# Define your custom function as a callable function\n",
    "\n",
    "def SayTool(input_result):\n",
    "    try:\n",
    "        if isinstance(input_result, list):\n",
    "            # Assuming input_result is a list of rows from the database\n",
    "            df = pd.DataFrame(input_result)\n",
    "        elif isinstance(input_result, str):\n",
    "            json_data = json.loads(input_result)\n",
    "            df = pd.DataFrame(json_data)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported input type\")\n",
    "\n",
    "        return df  # Return the DataFrame as output\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "hello = SayTool  # Assign the function without calling it\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "def CustomPredictionTool(input_question):\n",
    "    try:\n",
    "        # Make a request to the third-party API\n",
    "        api_url = \"https://docqnaaiml.azurewebsites.net/chat\"  # Replace with the actual API endpoint\n",
    "        payload = {\"question\": input_question}  # Adjust the payload as per the API's requirements\n",
    "\n",
    "        response = requests.post(api_url, json=payload)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            prediction = response.json()  # Parse the API response\n",
    "            return prediction  # Return the prediction from the API\n",
    "        else:\n",
    "            return \"API request failed with status code: \" + str(response.status_code)\n",
    "\n",
    "    except Exception as e:\n",
    "        return str(e)  # Return the error message if any error occurs\n",
    "# tools = [\n",
    "#     Tool(\n",
    "#         name=\"Chat Bot\",\n",
    "#         func=CustomPredictionTool,\n",
    "#         description=\"Use a third-party to answer the question.\"\n",
    "#     ),\n",
    "    \n",
    "# ]\n",
    "\n",
    "# agent_executor = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n",
    "# a=agent_executor.invoke({\"input\": \"give me detal of Proj_Milestone_ID is 1\"})\n",
    "# print(a)\n",
    "\n",
    "def Continue(a):\n",
    "    try:\n",
    "        database_user = \"anayasmi\"\n",
    "\n",
    "        database_password = \"Dcs_12345\"\n",
    "\n",
    "        database_server =\"anayasmi.database.windows.net\"\n",
    "\n",
    "        database_db = \"Anayasmi\"\n",
    "        dburi = f\"mssql+pymssql://{database_user}:{database_password}@{database_server}/{database_db}\"\n",
    "        db = SQLDatabase.from_uri(dburi)\n",
    "        db_chain = SQLDatabaseChain.from_llm(llm, db,verbose=True)\n",
    "        llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"Predict\",\n",
    "                func=hello,\n",
    "                description=\"useful only when DB tool result genrates then convert result of a database query to a pandas DataFrame.\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"Calculator\",\n",
    "                func=llm_math_chain.run,\n",
    "                description=\"useful for when you need to answer questions about math else skip this chain\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"DB\",\n",
    "                func=db_chain.run,\n",
    "                description=\"useful for when you need to answer questions from db and use it as second preference.LLM generates SQL query.\"  #\"useful for when you need to answer questions from db. Input should be in the form of a question containing full context and if prediction output asked provide data as input in sql format to say tool\"\n",
    "            ),\n",
    "        ]\n",
    "        agent_executor = initialize_agent(tools, llm, agent=AgentType.OPENAI_MULTI_FUNCTIONS,verbose=True)\n",
    "        answer=agent_executor.invoke({\"input\": a})\n",
    "        print(\"hii\")\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "    \n",
    "# # output=a.get(\"output\")\n",
    "# output=\"can you provide me data of milstone 1\"\n",
    "# Continue(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for sol chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis is a greeting, so I should respond with a greeting as well.\n",
      "Action: Say\n",
      "Action Input: \"Hello!\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mhello\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have responded with a greeting.\n",
      "Final Answer: Hello!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hii', 'output': 'Hello!'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.agents import Tool\n",
    "# from langchain.agents import AgentType\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "# from langchain.llms import OpenAI\n",
    "# from langchain.utilities import SerpAPIWrapper\n",
    "# from langchain.agents import initialize_agent\n",
    "# from langchain.agents import initialize_agent, AgentType, Tool\n",
    "# from langchain.chains import LLMMathChain\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.llms import OpenAI\n",
    "# from langchain.utilities import SerpAPIWrapper, SQLDatabase\n",
    "# from langchain_experimental.sql import SQLDatabaseChain\n",
    "# import os\n",
    "# from langchain.sql_database import SQLDatabase\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "\n",
    "# # Define your custom function as a callable function\n",
    "# def SayTool(input_result):\n",
    "#     return \"hello\"\n",
    "#     # try:\n",
    "#     #     # Assuming input_result is a list of rows from the database\n",
    "#     #     df = pd.DataFrame(input_result)\n",
    "#     #     return df  # Return the DataFrame as output\n",
    "#     # except Exception as e:\n",
    "#     #     return str(e) \n",
    "\n",
    "# database_user = \"amits\"\n",
    "\n",
    "# database_password = \"amit12345\"\n",
    "\n",
    "# database_server =\"dbserver\"\n",
    "\n",
    "# database_db = \"Nexum_Base\"\n",
    "# dburi = f\"mssql+pymssql://{database_user}:{database_password}@{database_server}:1433/{database_db}\"\n",
    "# llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "# hello = SayTool  # Assign the function without calling it\n",
    "# # db = SQLDatabase.from_uri(\"sqlite:///../../../../../notebooks/Chinook.db\")\n",
    "# # db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
    "# llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "\n",
    "# tools = [\n",
    "#     Tool(\n",
    "#         name=\"Say\",\n",
    "#         func=hello,\n",
    "#         description=\"use for greeting purpose\"\n",
    "#     ),\n",
    "#     Tool(\n",
    "#         name=\"Calculator\",\n",
    "#         func=llm_math_chain.run,\n",
    "#         description=\"useful for when you need to answer questions about math\"\n",
    "#     ),\n",
    "#     # Tool(\n",
    "#     #     name=\"DB\",\n",
    "#     #     func=db_chain.run,\n",
    "#     #     description=\"Useful for database queries. LLM generates SQL query.\"  #\"useful for when you need to answer questions from db. Input should be in the form of a question containing full context and if prediction output asked provide data as input in sql format to say tool\"\n",
    "#     # )\n",
    "# ]\n",
    "\n",
    "# agent_executor = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "# agent_executor.invoke({\"input\": \"hii\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
